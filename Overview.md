"""
ë¬¸ì„œ ë§¤í•‘ ìƒì„± í†µí•© ë„êµ¬
- Jinja2 í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
- LLM API í˜¸ì¶œ ë° ë§¤í•‘ ê²°ê³¼ íŒŒì‹±
"""

import json
from typing import Dict, List, Any, Optional
from jinja2 import Template
import anthropic  # ë˜ëŠ” openai ë“± ë‹¤ë¥¸ LLM ë¼ì´ë¸ŒëŸ¬ë¦¬


# Jinja2 í…œí”Œë¦¿ ì •ì˜
MAPPING_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²˜ë¦¬ëœ ë¬¸ì„œ(ìš”ì•½ë¬¸)ì™€ ì›ë³¸ ì†ŒìŠ¤ ë¬¸ì„œë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ì •í™•í•˜ê²Œ ë§¤í•‘í•´ì•¼ í•©ë‹ˆë‹¤.

## ì‘ì—… ê°œìš”
- **ì²˜ë¦¬ëœ ë¬¸ì„œ**: {{ structured_processed_doc.metadata.title }}
- **ì†ŒìŠ¤ ë¬¸ì„œ ìˆ˜**: {{ structured_source_docs|length }}ê°œ
- **ë§¤í•‘ ë°©ì‹**: ì²˜ë¦¬ëœ ë¬¸ì„œì˜ ê° ë¬¸ì¥ì´ ì–´ëŠ ì†ŒìŠ¤ ë¬¸ì„œì˜ ì–´ë–¤ ë¬¸ì¥ë“¤ì„ ì°¸ì¡°/ìš”ì•½í–ˆëŠ”ì§€ ì‹ë³„

## ì†ŒìŠ¤ ë¬¸ì„œë“¤

{% for source_doc in structured_source_docs %}
### ì†ŒìŠ¤ ë¬¸ì„œ {{ loop.index }}: {{ source_doc.metadata.title }}
**ë¬¸ì„œ ID**: `{{ source_doc.doc_id }}`
**ë¬¸ì¥ ëª©ë¡**:
{% for sentence in source_doc.content.sentences %}
- `{{ sentence.id }}` (ë¼ì¸ {{ sentence.lines|join(', ') }}): {{ sentence.text }}
{% endfor %}

{% endfor %}

## ì²˜ë¦¬ëœ ë¬¸ì„œ (ìš”ì•½ë¬¸)

**ë¬¸ì„œ ID**: `{{ structured_processed_doc.doc_id }}`
**ì œëª©**: {{ structured_processed_doc.metadata.title }}
**ë¬¸ì¥ ëª©ë¡**:
{% for sentence in structured_processed_doc.content.sentences %}
- `{{ sentence.id }}` (ë¼ì¸ {{ sentence.lines|join(', ') }}): {{ sentence.text }}
{% endfor %}

{% if existing_mappings %}
## ê¸°ì¡´ ë§¤í•‘ ì •ë³´ (ì°¸ê³ ìš©)

### ìš”ì•½ë¬¸ â†’ ì†ŒìŠ¤ ë¬¸ì„œ ë§¤í•‘
```json
{{ existing_mappings.summary_to_source | tojson(indent=2) }}
```

### ì†ŒìŠ¤ ë¬¸ì„œ â†’ ìš”ì•½ë¬¸ ë§¤í•‘
```json
{{ existing_mappings.source_to_summary | tojson(indent=2) }}
```

**ì£¼ì˜**: ê¸°ì¡´ ë§¤í•‘ì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ê²€ì¦í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”.
{% endif %}

## ë§¤í•‘ ê·œì¹™

1. **ì •í™•ì„±**: ìš”ì•½ë¬¸ì˜ ê° ë¬¸ì¥ì´ ì‹¤ì œë¡œ ì°¸ì¡°í•˜ëŠ” ì†ŒìŠ¤ ë¬¸ì¥ë“¤ë§Œ ë§¤í•‘
2. **ì™„ì „ì„±**: ëª¨ë“  ìš”ì•½ë¬¸ ë¬¸ì¥ì— ëŒ€í•´ ë§¤í•‘ ì œê³µ (ë§¤í•‘ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
3. **ë‹¤ì¤‘ ì°¸ì¡°**: í•˜ë‚˜ì˜ ìš”ì•½ë¬¸ ë¬¸ì¥ì´ ì—¬ëŸ¬ ì†ŒìŠ¤ ë¬¸ì¥ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìŒ
4. **êµì°¨ ë¬¸ì„œ**: ì—¬ëŸ¬ ì†ŒìŠ¤ ë¬¸ì„œì˜ ë¬¸ì¥ë“¤ì„ í†µí•©í•œ ê²½ìš° ëª¨ë‘ í¬í•¨
5. **ì–‘ë°©í–¥**: summary_to_sourceì™€ source_to_summary ëª¨ë‘ ìƒì„±

## ì¶œë ¥ í˜•ì‹

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë§¤í•‘ ì •ë³´ë¥¼ ë°˜í™˜í•˜ì„¸ìš”:

```json
{
  "summary_to_source": {
    "ì²˜ë¦¬ëœë¬¸ì„œ_ë¬¸ì¥ID": ["ì†ŒìŠ¤ë¬¸ì„œ_ë¬¸ì¥ID1", "ì†ŒìŠ¤ë¬¸ì„œ_ë¬¸ì¥ID2", ...],
    ...
  },
  "source_to_summary": {
    "ì†ŒìŠ¤ë¬¸ì„œ_ë¬¸ì¥ID": ["ì²˜ë¦¬ëœë¬¸ì„œ_ë¬¸ì¥ID1", ...],
    ...
  }
}
```

## ë¶„ì„ í”„ë¡œì„¸ìŠ¤

1. ê° ìš”ì•½ë¬¸ ë¬¸ì¥ì„ ì½ê³  í•µì‹¬ ë‚´ìš© íŒŒì•…
2. í•´ë‹¹ ë‚´ìš©ì´ ì–´ëŠ ì†ŒìŠ¤ ë¬¸ì„œì˜ ì–´ë–¤ ë¬¸ì¥ì—ì„œ ìœ ë˜í–ˆëŠ”ì§€ ì‹ë³„
3. ì˜ë¯¸ì  ìœ ì‚¬ì„±ê³¼ í‚¤ì›Œë“œ ì¼ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘
4. ì—¬ëŸ¬ ë¬¸ì¥ì´ í†µí•©ëœ ê²½ìš° ëª¨ë‘ í¬í•¨
5. ì–‘ë°©í–¥ ë§¤í•‘ì˜ ì¼ê´€ì„± ê²€ì¦

---

ì´ì œ ìœ„ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ **ì™„ì „í•˜ê³  ì •í™•í•œ ë§¤í•‘ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""


def generate_mapping_prompt(
    structured_source_docs: List[Dict[str, Any]],
    structured_processed_doc: Dict[str, Any],
    existing_mappings: Optional[Dict[str, Any]] = None
) -> str:
    """
    Jinja2 í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ë§¤í•‘ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        structured_source_docs: êµ¬ì¡°í™”ëœ ì†ŒìŠ¤ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        structured_processed_doc: êµ¬ì¡°í™”ëœ ì²˜ë¦¬ ë¬¸ì„œ
        existing_mappings: ê¸°ì¡´ ë§¤í•‘ ì •ë³´ (ì„ íƒì‚¬í•­)
    
    Returns:
        LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    template = Template(MAPPING_PROMPT_TEMPLATE)
    
    prompt = template.render(
        structured_source_docs=structured_source_docs,
        structured_processed_doc=structured_processed_doc,
        existing_mappings=existing_mappings
    )
    
    return prompt


def parse_mapping_response(response_text: str) -> Dict[str, Any]:
    """
    LLM ì‘ë‹µì—ì„œ JSON ë§¤í•‘ ì •ë³´ ì¶”ì¶œ
    
    Args:
        response_text: LLMì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    
    Returns:
        íŒŒì‹±ëœ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
    """
    # JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ
    import re
    
    # ```json ... ``` ë˜ëŠ” ``` ... ``` í˜•ì‹ ì°¾ê¸°
    json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
    
    if json_match:
        json_str = json_match.group(1)
    else:
        # ì½”ë“œ ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì°¾ê¸°
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
        else:
            raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        mappings = json.loads(json_str)
        return mappings
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")


def generate_mappings_with_llm(
    structured_source_docs: List[Dict[str, Any]],
    structured_processed_doc: Dict[str, Any],
    api_key: str,
    existing_mappings: Optional[Dict[str, Any]] = None,
    model: str = "claude-3-5-sonnet-20241022"
) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê°„ ë§¤í•‘ ìƒì„±
    
    Args:
        structured_source_docs: êµ¬ì¡°í™”ëœ ì†ŒìŠ¤ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        structured_processed_doc: êµ¬ì¡°í™”ëœ ì²˜ë¦¬ ë¬¸ì„œ
        api_key: Anthropic API í‚¤
        existing_mappings: ê¸°ì¡´ ë§¤í•‘ ì •ë³´ (ì„ íƒì‚¬í•­)
        model: ì‚¬ìš©í•  ëª¨ë¸ëª…
    
    Returns:
        ìƒì„±ëœ ë§¤í•‘ ì •ë³´
    """
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = generate_mapping_prompt(
        structured_source_docs,
        structured_processed_doc,
        existing_mappings
    )
    
    # Anthropic API í˜¸ì¶œ
    client = anthropic.Anthropic(api_key=api_key)
    
    message = client.messages.create(
        model=model,
        max_tokens=4096,
        messages=[
            {"role": "user", "content": prompt}
        ]
    )
    
    response_text = message.content[0].text
    
    # ì‘ë‹µ íŒŒì‹±
    mappings = parse_mapping_response(response_text)
    
    return mappings


def validate_mappings(
    mappings: Dict[str, Any],
    structured_source_docs: List[Dict[str, Any]],
    structured_processed_doc: Dict[str, Any]
) -> Dict[str, List[str]]:
    """
    ë§¤í•‘ì˜ ìœ íš¨ì„± ê²€ì¦
    
    Args:
        mappings: ê²€ì¦í•  ë§¤í•‘ ì •ë³´
        structured_source_docs: ì†ŒìŠ¤ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        structured_processed_doc: ì²˜ë¦¬ ë¬¸ì„œ
    
    Returns:
        ê²€ì¦ ê²°ê³¼ (errorsì™€ warnings)
    """
    errors = []
    warnings = []
    
    # ëª¨ë“  ë¬¸ì¥ ID ìˆ˜ì§‘
    source_sentence_ids = set()
    for doc in structured_source_docs:
        for sent in doc['content']['sentences']:
            source_sentence_ids.add(sent['id'])
    
    processed_sentence_ids = set(
        s['id'] for s in structured_processed_doc['content']['sentences']
    )
    
    # summary_to_source ê²€ì¦
    for proc_id, source_ids in mappings.get('summary_to_source', {}).items():
        if proc_id not in processed_sentence_ids:
            errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì²˜ë¦¬ ë¬¸ì„œ ë¬¸ì¥ ID: {proc_id}")
        
        for source_id in source_ids:
            if source_id not in source_sentence_ids:
                errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ ë¬¸ì¥ ID: {source_id}")
    
    # source_to_summary ê²€ì¦
    for source_id, proc_ids in mappings.get('source_to_summary', {}).items():
        if source_id not in source_sentence_ids:
            errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ ë¬¸ì¥ ID: {source_id}")
        
        for proc_id in proc_ids:
            if proc_id not in processed_sentence_ids:
                errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì²˜ë¦¬ ë¬¸ì„œ ë¬¸ì¥ ID: {proc_id}")
    
    # ì–‘ë°©í–¥ ì¼ê´€ì„± ê²€ì¦
    for proc_id, source_ids in mappings.get('summary_to_source', {}).items():
        for source_id in source_ids:
            reverse_mapping = mappings.get('source_to_summary', {}).get(source_id, [])
            if proc_id not in reverse_mapping:
                warnings.append(
                    f"ì–‘ë°©í–¥ ë¶ˆì¼ì¹˜: {proc_id} â†’ {source_id}ëŠ” ìˆì§€ë§Œ ì—­ë°©í–¥ ë§¤í•‘ ì—†ìŒ"
                )
    
    return {
        "errors": errors,
        "warnings": warnings
    }


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    # ì˜ˆì‹œ ë°ì´í„° (ì´ì „ structure_document í•¨ìˆ˜ë¡œ ìƒì„±ëœ ê²ƒ ê°€ì •)
    source_docs = [
        {
            "doc_id": "src_001",
            "metadata": {"title": "AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸"},
            "content": {
                "sentences": [
                    {"id": "src_001_s1", "text": "AI ìœ¤ë¦¬ ì›ì¹™ì˜ ì¤‘ìš”ì„±", "lines": [1]},
                    {"id": "src_001_s2", "text": "íˆ¬ëª…ì„±ê³¼ ê³µì •ì„±ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.", "lines": [2]}
                ]
            }
        }
    ]
    
    processed_doc = {
        "doc_id": "proc_001",
        "metadata": {"title": "AI ìœ¤ë¦¬ ìš”ì•½"},
        "content": {
            "sentences": [
                {"id": "proc_s1", "text": "AI ìœ¤ë¦¬ì™€ íˆ¬ëª…ì„±ì´ ì¤‘ìš”í•˜ë‹¤.", "lines": [1]}
            ]
        }
    }
    
    # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = generate_mapping_prompt(source_docs, processed_doc)
    print("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:")
    print(prompt[:500] + "...\n")
    
    # 2. LLMìœ¼ë¡œ ë§¤í•‘ ìƒì„± (API í‚¤ í•„ìš”)
    # mappings = generate_mappings_with_llm(
    #     source_docs,
    #     processed_doc,
    #     api_key="your-api-key"
    # )
    
    # 3. ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•œ ë§¤í•‘ ì˜ˆì‹œ
    mappings = {
        "summary_to_source": {
            "proc_s1": ["src_001_s1", "src_001_s2"]
        },
        "source_to_summary": {
            "src_001_s1": ["proc_s1"],
            "src_001_s2": ["proc_s1"]
        }
    }
    
    # 4. ë§¤í•‘ ê²€ì¦
    validation_result = validate_mappings(mappings, source_docs, processed_doc)
    
    print("âœ… ë§¤í•‘ ê²€ì¦ ì™„ë£Œ!")
    if validation_result['errors']:
        print(f"âŒ ì˜¤ë¥˜: {len(validation_result['errors'])}ê°œ")
        for error in validation_result['errors']:
            print(f"  - {error}")
    else:
        print("  ì˜¤ë¥˜ ì—†ìŒ")
    
    if validation_result['warnings']:
        print(f"âš ï¸  ê²½ê³ : {len(validation_result['warnings'])}ê°œ")
        for warning in validation_result['warnings']:
            print(f"  - {warning}")
    else:
        print("  ê²½ê³  ì—†ìŒ")
    
    # 5. ì „ì²´ ë°ì´í„° êµ¬ì¡°ì— ë§¤í•‘ ì¶”ê°€
    full_data = {
        "source_documents": source_docs,
        "processed_document": processed_doc,
        "mappings": mappings
    }
    
    print("\nâœ… ìµœì¢… ë°ì´í„° êµ¬ì¡°:")
    print(json.dumps(full_data, ensure_ascii=False, indent=2))


# ============================================================================
# OpenAI ì‚¬ìš© ë²„ì „ (ì„ íƒ)
# ============================================================================

def generate_mappings_with_openai(
    structured_source_docs: List[Dict[str, Any]],
    structured_processed_doc: Dict[str, Any],
    api_key: str,
    existing_mappings: Optional[Dict[str, Any]] = None,
    model: str = "gpt-4"
) -> Dict[str, Any]:
    """
    OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê°„ ë§¤í•‘ ìƒì„±
    """
    import openai
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = generate_mapping_prompt(
        structured_source_docs,
        structured_processed_doc,
        existing_mappings
    )
    
    # OpenAI API í˜¸ì¶œ
    openai.api_key = api_key
    
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )
    
    response_text = response.choices[0].message.content
    
    # ì‘ë‹µ íŒŒì‹±
    mappings = parse_mapping_response(response_text)
    
    return mappings


# ============================================================================
# ë°°ì¹˜ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
# ============================================================================

def update_mappings_batch(
    data_file: str,
    output_file: str,
    api_key: str,
    force_regenerate: bool = False
):
    """
    ì—¬ëŸ¬ ë¬¸ì„œì˜ ë§¤í•‘ì„ ì¼ê´„ ìƒì„±/ì—…ë°ì´íŠ¸
    
    Args:
        data_file: ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ
        api_key: LLM API í‚¤
        force_regenerate: ê¸°ì¡´ ë§¤í•‘ì´ ìˆì–´ë„ ì¬ìƒì„±í• ì§€ ì—¬ë¶€
    """
    # ë°ì´í„° ë¡œë“œ
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    source_docs = data.get('source_documents', [])
    processed_doc = data.get('processed_document')
    existing_mappings = data.get('mappings') if not force_regenerate else None
    
    print(f"ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ:")
    print(f"  - ì†ŒìŠ¤ ë¬¸ì„œ: {len(source_docs)}ê°œ")
    print(f"  - ì²˜ë¦¬ ë¬¸ì„œ: {processed_doc['metadata']['title']}")
    
    # ë§¤í•‘ ìƒì„±
    print("\nğŸ”„ ë§¤í•‘ ìƒì„± ì¤‘...")
    try:
        mappings = generate_mappings_with_llm(
            source_docs,
            processed_doc,
            api_key,
            existing_mappings
        )
        print("âœ… ë§¤í•‘ ìƒì„± ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ë§¤í•‘ ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # ê²€ì¦
    print("\nğŸ” ë§¤í•‘ ê²€ì¦ ì¤‘...")
    validation = validate_mappings(mappings, source_docs, processed_doc)
    
    if validation['errors']:
        print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {len(validation['errors'])}ê°œ ì˜¤ë¥˜")
        for error in validation['errors']:
            print(f"  - {error}")
        return
    
    if validation['warnings']:
        print(f"âš ï¸  {len(validation['warnings'])}ê°œ ê²½ê³ :")
        for warning in validation['warnings'][:5]:
            print(f"  - {warning}")
        if len(validation['warnings']) > 5:
            print(f"  ... ì™¸ {len(validation['warnings']) - 5}ê°œ")
    
    # ê²°ê³¼ ì €ì¥
    data['mappings'] = mappings
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # í†µê³„ ì¶œë ¥
    summary_count = len(mappings.get('summary_to_source', {}))
    source_count = len(mappings.get('source_to_summary', {}))
    print(f"\nğŸ“Š ë§¤í•‘ í†µê³„:")
    print(f"  - ìš”ì•½ë¬¸ ë¬¸ì¥: {summary_count}ê°œ")
    print(f"  - ë§¤í•‘ëœ ì†ŒìŠ¤ ë¬¸ì¥: {source_count}ê°œ")


# ============================================================================
# CLI ì¸í„°í˜ì´ìŠ¤
# ============================================================================

if __name__ == "__main__" and len(__import__('sys').argv) > 1:
    import sys
    import argparse
    
    parser = argparse.ArgumentParser(description='ë¬¸ì„œ ë§¤í•‘ ìƒì„± ë„êµ¬')
    parser.add_argument('input', help='ì…ë ¥ JSON íŒŒì¼')
    parser.add_argument('output', help='ì¶œë ¥ JSON íŒŒì¼')
    parser.add_argument('--api-key', required=True, help='LLM API í‚¤')
    parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ë§¤í•‘ ë¬´ì‹œí•˜ê³  ì¬ìƒì„±')
    parser.add_argument('--model', default='claude-3-5-sonnet-20241022', help='ì‚¬ìš©í•  ëª¨ë¸')
    
    args = parser.parse_args()
    
    update_mappings_batch(
        args.input,
        args.output,
        args.api_key,
        args.force
    )
