"""
ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„± ëª¨ë“ˆ
"""

import os
import json
from typing import Dict, Any, List, Optional
from openai import OpenAI
import anthropic

from app.core.prompts.prompt_manager import get_prompt_manager


def generate_custom_document_with_openai(
    source_documents: List[Dict[str, Any]],
    user_requirements: str,
    api_key: Optional[str] = None,
    model: Optional[str] = None
) -> Dict[str, Any]:
    """
    OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„±

    Args:
        source_documents: ì†ŒìŠ¤ ë¬¸ì„œ ë°°ì—´ (êµ¬ì¡°í™”ëœ í˜•ì‹)
        user_requirements: ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ (ììœ  í…ìŠ¤íŠ¸)
        api_key: OpenAI API í‚¤
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4o-mini)

    Returns:
        {
            "title": str,
            "content": str,
            "sentences": [
                {
                    "text": str,
                    "source_references": List[str]
                }
            ],
            "metadata": Dict[str, Any]
        }
    """
    # API í‚¤ í™•ì¸
    if api_key is None:
        api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    if model is None:
        model = "gpt-4o-mini"

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=api_key)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt_manager = get_prompt_manager()

    template_variables = {
        'source_documents': source_documents,
        'user_requirements': user_requirements
    }

    prompt = prompt_manager.render(
        yaml_file='custom_generation_prompts.yaml',
        task_id='custom_document_generation',
        variables=template_variables
    )

    print(f"ğŸ¤– OpenAI ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„± ì‹œì‘ - ëª¨ë¸: {model}")
    print(f"ğŸ“ ì†ŒìŠ¤ ë¬¸ì„œ ìˆ˜: {len(source_documents)}")
    print(f"ğŸ“‹ ìš”êµ¬ì‚¬í•­ ê¸¸ì´: {len(user_requirements)} ë¬¸ì")
    print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")

    # OpenAI API í˜¸ì¶œ
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        temperature=0.5,  # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
        max_tokens=4000,
        response_format={"type": "json_object"}  # JSON ëª¨ë“œ ê°•ì œ
    )

    response_text = response.choices[0].message.content.strip()

    print(f"âœ… OpenAI ì‘ë‹µ ë°›ìŒ - ê¸¸ì´: {len(response_text)} ë¬¸ì")

    # JSON íŒŒì‹±
    try:
        result = json.loads(response_text)
        print(f"âœ… JSON íŒŒì‹± ì„±ê³µ")
        print(f"ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ ì œëª©: {result.get('title', 'N/A')}")
        print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì¥ ìˆ˜: {len(result.get('sentences', []))}")

        # ê²€ì¦
        if 'title' not in result or 'content' not in result or 'sentences' not in result:
            raise ValueError("í•„ìˆ˜ í•„ë“œ(title, content, sentences)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")

        return result

    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")


def generate_custom_document_with_anthropic(
    source_documents: List[Dict[str, Any]],
    user_requirements: str,
    api_key: Optional[str] = None,
    model: Optional[str] = None
) -> Dict[str, Any]:
    """
    Anthropic Claudeë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„±

    Args:
        source_documents: ì†ŒìŠ¤ ë¬¸ì„œ ë°°ì—´
        user_requirements: ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­
        api_key: Anthropic API í‚¤
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: claude-3-5-sonnet-20241022)

    Returns:
        ìƒì„± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # API í‚¤ í™•ì¸
    if api_key is None:
        api_key = os.getenv("ANTHROPIC_API_KEY")

    if not api_key:
        raise ValueError("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    if model is None:
        model = "claude-3-5-sonnet-20241022"

    # Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = anthropic.Anthropic(api_key=api_key)

    # í”„ë¡¬í”„íŠ¸ ìƒì„± (OpenAIì™€ ë™ì¼í•œ í…œí”Œë¦¿ ì‚¬ìš©)
    prompt_manager = get_prompt_manager()

    template_variables = {
        'source_documents': source_documents,
        'user_requirements': user_requirements
    }

    prompt = prompt_manager.render(
        yaml_file='custom_generation_prompts.yaml',
        task_id='custom_document_generation',
        variables=template_variables
    )

    print(f"ğŸ¤– Anthropic ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„± ì‹œì‘ - ëª¨ë¸: {model}")
    print(f"ğŸ“ ì†ŒìŠ¤ ë¬¸ì„œ ìˆ˜: {len(source_documents)}")
    print(f"ğŸ“‹ ìš”êµ¬ì‚¬í•­ ê¸¸ì´: {len(user_requirements)} ë¬¸ì")

    # API í˜¸ì¶œ
    response = client.messages.create(
        model=model,
        max_tokens=4000,
        temperature=0.5,
        messages=[
            {
                "role": "user",
                "content": prompt
            }
        ]
    )

    response_text = response.content[0].text.strip()

    print(f"âœ… Anthropic ì‘ë‹µ ë°›ìŒ - ê¸¸ì´: {len(response_text)} ë¬¸ì")

    # JSON íŒŒì‹±
    try:
        # ClaudeëŠ” ê°€ë” ```json ... ``` í˜•íƒœë¡œ ê°ìŒ€ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°
        if response_text.startswith("```json"):
            response_text = response_text.replace("```json", "").replace("```", "").strip()
        elif response_text.startswith("```"):
            response_text = response_text.replace("```", "").strip()

        result = json.loads(response_text)
        print(f"âœ… JSON íŒŒì‹± ì„±ê³µ")
        print(f"ğŸ“„ ìƒì„±ëœ ë¬¸ì„œ ì œëª©: {result.get('title', 'N/A')}")
        print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì¥ ìˆ˜: {len(result.get('sentences', []))}")

        # ê²€ì¦
        if 'title' not in result or 'content' not in result or 'sentences' not in result:
            raise ValueError("í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")

        return result

    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")


def generate_custom_document(
    source_documents: List[Dict[str, Any]],
    user_requirements: str,
    llm_provider: str = "openai",
    api_key: Optional[str] = None,
    model: Optional[str] = None
) -> Dict[str, Any]:
    """
    LLM ì œê³µìì— ë”°ë¼ ì»¤ìŠ¤í…€ ë¬¸ì„œ ìƒì„±

    Args:
        source_documents: ì†ŒìŠ¤ ë¬¸ì„œ ë°°ì—´
        user_requirements: ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­
        llm_provider: LLM ì œê³µì (openai, anthropic)
        api_key: API í‚¤
        model: ëª¨ë¸ëª…

    Returns:
        ìƒì„± ê²°ê³¼
    """
    if llm_provider == "openai":
        return generate_custom_document_with_openai(
            source_documents=source_documents,
            user_requirements=user_requirements,
            api_key=api_key,
            model=model
        )
    elif llm_provider == "anthropic":
        return generate_custom_document_with_anthropic(
            source_documents=source_documents,
            user_requirements=user_requirements,
            api_key=api_key,
            model=model
        )
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {llm_provider}")
